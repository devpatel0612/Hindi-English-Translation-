{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export SP_DIR=$CONDA_PREFIX/lib/python3.11/site-packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 17:45:31.666902: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-02 17:45:32.566376: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-02 17:45:33.623671: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile(\"/home/manogna/Machine-Learning-Collection/ML/Pytorch/more_advanced/Seq2Seq/archive(2).zip\", 'r') as zip_ref:\n",
    "#     zip_ref.extractall(\"/home/manogna/Machine-Learning-Collection/ML/Pytorch/more_advanced/Seq2Seq/Hindi-English \" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/manogna/Machine-Learning-Collection/ML/Pytorch/more_advanced/Seq2Seq\n"
     ]
    }
   ],
   "source": [
    "cd /home/manogna/Machine-Learning-Collection/ML/Pytorch/more_advanced/Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install inltk\n",
    "from inltk.inltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint\n",
    "\n",
    "# spacy_ger = spacy.load(\"de_core_news_sm\")\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_hin(text):\n",
    "    tokens =  tokenize(text,\"hi\")\n",
    "    return ' '.join(tokens).lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi = Field(tokenize=tokenize_hin, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = Field(\n",
    "    tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchtext\n",
    "from torchtext.data import Field, TabularDataset\n",
    "\n",
    "\n",
    "# Read the CSV file using pandas\n",
    "csv_file = \"/home/manogna/Machine-Learning-Collection/ML/Pytorch/more_advanced/Seq2Seq/Hindi-English /hindi_english_parallel.csv\"  # Replace with the path to your CSV file\n",
    "df = pd.read_csv(csv_file, nrows=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें</td>\n",
       "      <td>Give your application an accessibility workout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>एक्सेर्साइसर पहुंचनीयता अन्वेषक</td>\n",
       "      <td>Accerciser Accessibility Explorer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>निचले पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>The default plugin layout for the bottom panel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>The default plugin layout for the top panel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...</td>\n",
       "      <td>A list of plugins that are disabled by default</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               hindi  \\\n",
       "0    अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें   \n",
       "1                    एक्सेर्साइसर पहुंचनीयता अन्वेषक   \n",
       "2              निचले पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "3               ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "4  उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...   \n",
       "\n",
       "                                          english  \n",
       "0  Give your application an accessibility workout  \n",
       "1               Accerciser Accessibility Explorer  \n",
       "2  The default plugin layout for the bottom panel  \n",
       "3     The default plugin layout for the top panel  \n",
       "4  A list of plugins that are disabled by default  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['english']=df['english'].apply(lambda x: str(x))\n",
    "df['hindi']=df['hindi'].apply(lambda x: str(x))\n",
    "df['english']=df['english'].apply(lambda x: x.lower())\n",
    "df['hindi']=df['hindi'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hindi'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['english']=df['english'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "df['hindi']=df['hindi'].apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें</td>\n",
       "      <td>give your application an accessibility workout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>एक्सेर्साइसर पहुंचनीयता अन्वेषक</td>\n",
       "      <td>accerciser accessibility explorer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>निचले पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>the default plugin layout for the bottom panel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>the default plugin layout for the top panel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...</td>\n",
       "      <td>a list of plugins that are disabled by default</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               hindi  \\\n",
       "0    अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें   \n",
       "1                    एक्सेर्साइसर पहुंचनीयता अन्वेषक   \n",
       "2              निचले पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "3               ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "4  उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...   \n",
       "\n",
       "                                          english  \n",
       "0  give your application an accessibility workout  \n",
       "1               accerciser accessibility explorer  \n",
       "2  the default plugin layout for the bottom panel  \n",
       "3     the default plugin layout for the top panel  \n",
       "4  a list of plugins that are disabled by default  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "df['english']=df['english'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "df['hindi']=df['hindi'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें</td>\n",
       "      <td>give your application an accessibility workout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>एक्सेर्साइसर पहुंचनीयता अन्वेषक</td>\n",
       "      <td>accerciser accessibility explorer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>निचले पटल के लिए डिफोल्ट प्लगइन खाका</td>\n",
       "      <td>the default plugin layout for the bottom panel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ऊपरी पटल के लिए डिफोल्ट प्लगइन खाका</td>\n",
       "      <td>the default plugin layout for the top panel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>उन प्लगइनों की सूची जिन्हें डिफोल्ट रूप से निष...</td>\n",
       "      <td>a list of plugins that are disabled by default</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               hindi  \\\n",
       "0    अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें   \n",
       "1                    एक्सेर्साइसर पहुंचनीयता अन्वेषक   \n",
       "2               निचले पटल के लिए डिफोल्ट प्लगइन खाका   \n",
       "3                ऊपरी पटल के लिए डिफोल्ट प्लगइन खाका   \n",
       "4  उन प्लगइनों की सूची जिन्हें डिफोल्ट रूप से निष...   \n",
       "\n",
       "                                          english  \n",
       "0  give your application an accessibility workout  \n",
       "1               accerciser accessibility explorer  \n",
       "2  the default plugin layout for the bottom panel  \n",
       "3     the default plugin layout for the top panel  \n",
       "4  a list of plugins that are disabled by default  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_digits = str.maketrans('', '', digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{48: None,\n",
       " 49: None,\n",
       " 50: None,\n",
       " 51: None,\n",
       " 52: None,\n",
       " 53: None,\n",
       " 54: None,\n",
       " 55: None,\n",
       " 56: None,\n",
       " 57: None}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "df['english']=df['english'].apply(lambda x: x.translate(remove_digits))\n",
    "df['hindi']=df['hindi'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "df['hindi'] = df['hindi'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "df['english']=df['english'].apply(lambda x: x.strip())\n",
    "df['hindi']=df['hindi'].apply(lambda x: x.strip())\n",
    "df['english']=df['english'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "df['hindi']=df['hindi'].apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, valid_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "\n",
    "# Convert the dataframes back to CSV files\n",
    "train_df.to_csv(\"train_data.csv\", index=False, header=False)\n",
    "valid_df.to_csv(\"valid_data.csv\", index=False, header=False)\n",
    "test_df.to_csv(\"test_data.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TabularDataset objects for training, validation, and test sets\n",
    "train_data, valid_data, test_data = torchtext.data.TabularDataset.splits(\n",
    "    path=\"/home/manogna/Machine-Learning-Collection/ML/Pytorch/more_advanced/Seq2Seq\", format=\"csv\",\n",
    "    train=\"train_data.csv\",\n",
    "    validation=\"valid_data.csv\",\n",
    "    test=\"test_data.csv\",\n",
    "    fields=[(\"hindi\", hindi), (\"english\", english)],\n",
    "    skip_header=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "english.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (seq_length, N, hidden_size)\n",
    "\n",
    "        return hidden, cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n",
    "        # is 1 here because we are sending in a single word and not a sentence\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "        # outputs shape: (1, N, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs)\n",
    "\n",
    "        # predictions shape: (1, N, length_target_vocabulary) to send it to\n",
    "        # loss function we want it to be (N, length_target_vocabulary) so we're\n",
    "        # just gonna remove the first dim\n",
    "        predictions = predictions.squeeze(0)\n",
    "\n",
    "        return predictions, hidden, cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]  #Probable size is (target_len,N)\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(english.vocab)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "\n",
    "        hidden, cell = self.encoder(source)\n",
    "\n",
    "        # Grab the first input to the Decoder which will be <SOS> token\n",
    "        x = target[0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # Use previous hidden, cell as context from encoder at start\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "\n",
    "            # Store next output prediction\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            # With probability of teacher_force_ratio we take the actual next word\n",
    "            # otherwise we take the word that the Decoder predicted it to be.\n",
    "            # Teacher Forcing is used so that the model gets used to seeing\n",
    "            # similar inputs at training and testing time, if teacher forcing is 1\n",
    "            # then inputs at test time might be completely different than what the\n",
    "            # network is used to. This was a long comment.\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "## We're ready to define everything we need for training our Seq2Seq model ###\n",
    "\n",
    "# Training hyperparameters\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "\n",
    "# Model hyperparameters\n",
    "load_model = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size_encoder = len(hindi.vocab)\n",
    "input_size_decoder = len(english.vocab)\n",
    "output_size = len(english.vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024  # Needs to be the same for both RNN's\n",
    "num_layers = 2\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CUDA devices: 2\n",
      "CUDA Device 0 : GeForce RTX 2080 Ti\n",
      "CUDA Device 1 : GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available CUDA devices\n",
    "    num_devices = torch.cuda.device_count()\n",
    "    print(\"Number of CUDA devices:\", num_devices)\n",
    "    \n",
    "    # Iterate over the available CUDA devices\n",
    "    for i in range(num_devices):\n",
    "        device_name = torch.cuda.get_device_name(i)\n",
    "        print(\"CUDA Device\", i, \":\", device_name)\n",
    "else:\n",
    "    print(\"CUDA is not available on this system.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_devices = torch.cuda.device_count()\n",
    "num_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.hindi),\n",
    "    device=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_net = Encoder(\n",
    "    input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"खाली बची अतिरिक्त जगह पर कुछ ले जाएँ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['alidate', 'distance', 'services', 'https', 'enable', 'well', 'well', 'well', 'well', 'prints', 'well', 'well', 'well', 'well', 'kind', 'kind', 'echo', 'echo', 'versions', 'name', 'name', 'mailboxes', 'scope', 'thorough', 'distance', 'services', 'camelot', 'thorough', 'thorough', 'bison', 'mostly', 'several', 'mostly', 'forty', 'five', 'several', 'introduced', 'introduced', 'tommy', 'introduced', 'introduced', 'tommy', 'introduced', 'default', 'default', 'reject', 'gameplay', 'treize', 'extension', 'eyetracker']\n",
      "[Epoch 1 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['description', '<eos>']\n",
      "[Epoch 2 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['description', '<eos>']\n",
      "[Epoch 3 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['page', '<eos>']\n",
      "[Epoch 4 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['cover', '<eos>']\n",
      "[Epoch 5 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['homogeneous', '<eos>']\n",
      "[Epoch 6 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['page', '<eos>']\n",
      "[Epoch 7 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['homogeneous', '<eos>']\n",
      "[Epoch 8 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['homogeneous', '<eos>']\n",
      "[Epoch 9 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 10 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 11 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 12 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 13 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 14 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 15 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['homogeneous', '<eos>']\n",
      "[Epoch 16 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['symboldb', '<eos>']\n",
      "[Epoch 17 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['best', '<eos>']\n",
      "[Epoch 18 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 19 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['page', '<eos>']\n",
      "[Epoch 20 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 21 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 22 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['address', '<eos>']\n",
      "[Epoch 23 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['format', '<eos>']\n",
      "[Epoch 24 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 25 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 26 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 27 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 28 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['page', '<eos>']\n",
      "[Epoch 29 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['address', '<eos>']\n",
      "[Epoch 30 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['appearance', '<eos>']\n",
      "[Epoch 31 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 32 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 33 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['format', '<eos>']\n",
      "[Epoch 34 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['except', '<eos>']\n",
      "[Epoch 35 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['print', '<eos>']\n",
      "[Epoch 36 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['print', '<eos>']\n",
      "[Epoch 37 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['except', '<eos>']\n",
      "[Epoch 38 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 39 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['page', '<eos>']\n",
      "[Epoch 40 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['page', '<eos>']\n",
      "[Epoch 41 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['page', '<eos>']\n",
      "[Epoch 42 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['page', '<eos>']\n",
      "[Epoch 43 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 44 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 45 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['page', '<eos>']\n",
      "[Epoch 46 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['print', '<eos>']\n",
      "[Epoch 47 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['loop', '<eos>']\n",
      "[Epoch 48 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['page', '<eos>']\n",
      "[Epoch 49 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['page', '<eos>']\n",
      "[Epoch 50 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['page', '<eos>']\n",
      "[Epoch 51 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['loop', '<eos>']\n",
      "[Epoch 52 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['page', '<eos>']\n",
      "[Epoch 53 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 54 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['properties', '<eos>']\n",
      "[Epoch 55 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 56 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 57 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['page', '<eos>']\n",
      "[Epoch 58 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['page', '<eos>']\n",
      "[Epoch 59 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 60 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 61 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 62 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 63 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 64 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 65 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 66 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['appearance', '<eos>']\n",
      "[Epoch 67 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 68 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['appearance', '<eos>']\n",
      "[Epoch 69 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['page', '<eos>']\n",
      "[Epoch 70 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 71 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 72 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 73 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 74 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 75 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['properties', '<eos>']\n",
      "[Epoch 76 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 77 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['path', '<eos>']\n",
      "[Epoch 78 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 79 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['properties', '<eos>']\n",
      "[Epoch 80 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['page', '<eos>']\n",
      "[Epoch 81 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 82 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['page', '<eos>']\n",
      "[Epoch 83 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['page', '<eos>']\n",
      "[Epoch 84 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 85 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 86 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 87 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['path', '<eos>']\n",
      "[Epoch 88 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 89 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['appearance', '<eos>']\n",
      "[Epoch 90 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 91 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 92 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['duration', '<eos>']\n",
      "[Epoch 93 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 94 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['appearance', '<eos>']\n",
      "[Epoch 95 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 96 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['attributes', '<eos>']\n",
      "[Epoch 97 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['path', '<eos>']\n",
      "[Epoch 98 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['duration', '<eos>']\n",
      "[Epoch 99 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['path', '<eos>']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 52\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[39m# Plot to tensorboard\u001b[39;00m\n\u001b[1;32m     48\u001b[0m         \u001b[39m# writer.add_scalar(\"Training loss\", loss, global_step=step)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m         step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 52\u001b[0m score \u001b[39m=\u001b[39m bleu(test_data[\u001b[39m1\u001b[39;49m:\u001b[39m100\u001b[39;49m], model, hindi, english, device)\n\u001b[1;32m     53\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBleu score \u001b[39m\u001b[39m{\u001b[39;00mscore\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Machine-Learning-Collection/ML/Pytorch/more_advanced/Seq2Seq/utils.py:107\u001b[0m, in \u001b[0;36mbleu\u001b[0;34m(data, model, german, english, device)\u001b[0m\n\u001b[1;32m    104\u001b[0m outputs \u001b[39m=\u001b[39m []\n\u001b[1;32m    106\u001b[0m \u001b[39mfor\u001b[39;00m example \u001b[39min\u001b[39;00m data:\n\u001b[0;32m--> 107\u001b[0m     src \u001b[39m=\u001b[39m \u001b[39mvars\u001b[39;49m(example)[\u001b[39m\"\u001b[39;49m\u001b[39msrc\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m    108\u001b[0m     trg \u001b[39m=\u001b[39m \u001b[39mvars\u001b[39m(example)[\u001b[39m\"\u001b[39m\u001b[39mtrg\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    110\u001b[0m     prediction \u001b[39m=\u001b[39m translate_sentence(model, src, german, english, device)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'src'"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "    checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "    save_checkpoint(checkpoint)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    translated_sentence = translate_sentence(\n",
    "        model, sentence, hindi, english, device, max_length=50\n",
    "    )\n",
    "\n",
    "    print(f\"Translated example sentence: \\n {translated_sentence}\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        # Get input and targets and get to cuda\n",
    "        inp_data = batch.hindi.to(device)\n",
    "        target = batch.english.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(inp_data, target)\n",
    "\n",
    "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
    "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
    "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
    "        # way that we have output_words * batch_size that we want to send in into\n",
    "        # our cost function, so we need to do some reshapin. While we're at it\n",
    "        # Let's also remove the start token while we're at it\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "        # within a healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Plot to tensorboard\n",
    "        # writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        step += 1\n",
    "\n",
    "\n",
    "score = bleu(test_data[1:100], model, hindi, english, device)\n",
    "print(f\"Bleu score {score*100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best', '<eos>']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"खाली बची अतिरिक्त जगह पर कुछ ले जाएँ\"\n",
    "\n",
    "translated_sentence = translate_sentence(\n",
    "        model, sentence, hindi, english, device, max_length=50)\n",
    "\n",
    "translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
